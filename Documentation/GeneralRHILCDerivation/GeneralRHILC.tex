\documentclass[landscape]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{bbold}
\usepackage{soul}
\usepackage{color}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{float}
\usepackage{tabularx}
\usepackage[margin=0.25in]{geometry}
\begin{document}
\section{Introduction}
This document is a derivation of the general form of learning filters for receding horizon iterative learning control.  Suppose that we are given a lifted system model of the form
\begin{align}
x_{j+1} 
& = x_j + G_j(u_{j+1} - u_j) + F_j \left(x^0_{j+1} - x^0_j\right)\\
& = x_j + G_j(u_{j+1} - u_j) + F_j \left(x^F_{j} - x^0_j\right)\\
& = x_j + G_j(u_{j+1} - u_j) + F_j \left(E_F-E_I\right)x_j\\
& = x_j + G_j(u_{j+1} - u_j) + F_j E_F x_j - F_j E_I x_j\\
& = x_j + G_j(u_{j+1} - u_j) + \hat{F}_j x_j\\
& = x_j + \hat{F}_j x_j + G_j(u_{j+1} - u_j) \\
& = \left(\mathbb{I}+\hat{F}_j\right)x_j + G_j(u_{j+1} - u_j)
\end{align}
Then our predictions of the state sequence at $j+2$, $j+3$, and so on are
\begin{align}
x_{j+2} 
& = x_j + G_j(u_{j+2}-u_j) + F_j \left(x^0_{j+2}-x^0_{j}\right)\\
& = x_j + G_j(u_{j+2}-u_j) + F_j \left(E_F x_{j+1}-E_I x_{j}\right)\\
& = x_j + G_j(u_{j+2}-u_j) + F_j E_F x_{j+1} - F_j E_I x_{j}\\
& = x_j + G_j(u_{j+2}-u_j) - F_j E_I x_{j}   + F_j E_F x_{j+1}\\
& = x_j + G_j(u_{j+2}-u_j) - F_j E_I x_{j}   + F_j E_F \left(x_j + G_j(u_{j+1} - u_j) + F_j E_F x_j - F_j E_I x_j\right)\\
& = x_j + G_j(u_{j+2}-u_j) - F_j E_I x_{j}   + F_j E_F x_j + F_j E_F G_j(u_{j+1} - u_j) + F_j E_F F_j E_F x_j - F_j E_F F_j E_I x_j\\
& = x_j + G_j(u_{j+2}-u_j) + F_j E_F G_j(u_{j+1} - u_j) - F_j E_I x_{j}   + F_j E_F x_j + F_j E_F F_j E_F x_j - F_j E_F F_j E_I x_j\\
& = x_j + G_j(u_{j+2}-u_j) + F_j E_F G_j(u_{j+1} - u_j) + F_j \left( E_F -E_I \right) x_{j} + F_j E_F F_j E_F x_j - F_j E_F F_j E_I x_j\\
& = x_j + G_j(u_{j+2}-u_j) + F_j E_F G_j(u_{j+1} - u_j) + F_j \left( E_F -E_I \right) x_{j} + F_j E_F F_j \left( E_F - E_I \right) x_j
\end{align}

\begin{align}
x_{j+3} 
& = x_j + G_j (u_{j+3} - u_j) + F_j \left(x^0_{j+3} - x^0_{j}\right)\\
& = x_j + G_j (u_{j+3} - u_j) + F_j \left(E_F x_{j+2} - E_I x_{j}\right)\\
& = x_j + G_j (u_{j+3} - u_j) + F_j E_F x_{j+2} - F_j E_I x_{j}\\
& = x_j + G_j (u_{j+3} - u_j) - F_j E_I x_{j} + F_j E_F x_{j+2} \\
& = x_j + G_j (u_{j+3} - u_j) - F_j E_I x_{j} + F_j E_F \left( x_j + G_j(u_{j+2}-u_j) + F_j E_F G_j(u_{j+1} - u_j) - F_j E_I x_{j}   + F_j E_F x_j + F_j E_F F_j E_F x_j - F_j E_F F_j E_I x_j \right) \\
& = x_j + G_j (u_{j+3} - u_j) - F_j E_I x_{j} + F_j E_F x_j + F_j E_F G_j(u_{j+2}-u_j) + F_j E_F F_j E_F G_j(u_{j+1} - u_j) - F_j E_F F_j E_I x_{j}   + F_j E_F F_j E_F x_j + F_j E_F F_j E_F F_j E_F x_j - F_j E_F F_j E_F F_j E_I x_j  \\
& = x_j + G_j (u_{j+3} - u_j) + F_j E_F G_j(u_{j+2}-u_j) + F_j E_F F_j E_F G_j(u_{j+1} - u_j) - F_j E_I x_{j} + F_j E_F x_j  - F_j E_F F_j E_I x_{j}   + F_j E_F F_j E_F x_j + F_j E_F F_j E_F F_j E_F x_j - F_j E_F F_j E_F F_j E_I x_j  \\
& = x_j + G_j (u_{j+3} - u_j) + F_j E_F G_j(u_{j+2}-u_j) + F_j E_F F_j E_F G_j(u_{j+1} - u_j) + F_j \left( E_F - E_I \right) x_{j} - F_j E_F F_j E_I x_{j}   + F_j E_F F_j E_F x_j + F_j E_F F_j E_F F_j E_F x_j - F_j E_F F_j E_F F_j E_I x_j  \\
& = x_j + G_j (u_{j+3} - u_j) + F_j E_F G_j(u_{j+2}-u_j) + F_j E_F F_j E_F G_j(u_{j+1} - u_j) + F_j \left( E_F - E_I \right) x_{j} + F_j E_F F_j \left( F_F - E_I \right) x_{j} + F_j E_F F_j E_F F_j \left( E_F -E_I \right) x_j 
\end{align}

\begin{align}
x_{j+1} & = x_j 					 &  							 &                  + G_j(u_{j+1} - u_j)& + F_j \left( E_F- E_I \right)& x_j\\ 
x_{j+2} & = x_j 				     &             + G_j(u_{j+2}-u_j)&	        + F_j E_F G_j(u_{j+1} - u_j)& + F_j \left( E_F -E_I \right)& x_{j} + F_j E_F F_j \left( E_F - E_I \right) x_j\\
x_{j+3} & = x_j + G_j (u_{j+3} - u_j)& 	   + F_j E_F G_j(u_{j+2}-u_j)& 	+ F_j E_F F_j E_F G_j(u_{j+1} - u_j)& + F_j \left( E_F - E_I\right)& x_{j} + F_j E_F F_j \left( F_F - E_I \right) x_{j} + F_j E_F F_j E_F F_j \left( E_F -E_I \right) x_j 
\end{align}

Therefore, if we form the uber-lyfted vectors
\begin{align}
\mathbf{x}_{j+1} \triangleq \begin{bmatrix} x_{j+1} \\ x_{j+2} \\ \vdots \\ x_{j+N-1} \\ x_{j+N}\end{bmatrix}, \quad 
\mathbf{u}_{j+1} \triangleq \begin{bmatrix} u_{j+1} \\ u_{j+2} \\ \vdots \\ u_{j+N-1} \\ u_{j+N}\end{bmatrix}
\end{align}
then we can write an expression for $\mathbf{x}_{j+1}$ in terms of $\mathbf{u}_{j+1}$
\begin{align}
\mathbf{x}_{j+1} 
& = \mathbf{I}_x x_j + \begin{bmatrix} \mathbb{I} \\ \mathbb{I} + F_j E_F \\ \mathbb{I} + F_j E_F + F_j E_F F_j E_F\\ \vdots \\ \mathbb{I} + \sum_{k = 1}^{N_i-1} \prod_{m=1}^{k}F_j E_F \\ \mathbb{I} + \sum_{k = 1}^{N_i} \prod_{m=1}^{k}F_j E_F \end{bmatrix} F_j \left(E_F - E_I\right)x_j
+\begin{bmatrix} 
G_j & \mathbb{0} & \mathbb{0} & \hdots & \mathbb{0} \\
F_j E_F G_j   & G_j & \mathbb{0} & \hdots & \mathbb{0} \\
F_j E_F F_j E_F G_j   & F_j E_F G_j & G_j & \hdots & \mathbb{0} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
\left(\prod_{m=1}^{N_i-1}F_j E_F\right)G_j & \left(\prod_{m=1}^{N_i-2}F_j E_F\right)G_j & \hdots & G_j & \mathbb{0} \\
\left(\prod_{m=1}^{N_i}F_j E_F\right)G_j & \left(\prod_{m=1}^{N_i-1}F_j E_F\right)G_j & \hdots & F_j E_F G_j & G_j
\end{bmatrix}
\left(\mathbf{u}_{j+1}- \mathbf{I}_u u_j \right)
\end{align}
Here, $\mathbf{I}\triangleq \begin{bmatrix} \mathbb{I} & \hdots & \mathbb{I} \end{bmatrix}^T$If we define $\mathbf{F}_j$ to be the first matrix, and $\mathbf{G}_j$ to be the second matrix, then our system model as lifted in the iteration domain is
\begin{align}
\mathbf{x}_{j+1} = \left(\mathbf{I}_x +\mathbf{F}_j \right)x_j + \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_u u_j \right)
\end{align}
Next, form the uber-lyfted vector $\mathbf{r} \triangleq \mathbf{I} r$, then the uber-lyfted error sequence $\mathbf{e}_{j+1}$ is
\begin{align}
\mathbf{e}_{j+1} 
& = \mathbf{I}_r r - \mathbf{x}_{j+1}\\
& = \mathbf{I}_r r - \left(\mathbf{I}_x +\mathbf{F}_j \right)x_j - \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_u u_j \right)\\
& = \mathbf{I}_r r - \mathbf{I}_x x_j - \mathbf{F}_j x_j - \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_u u_j \right)\\
& = \mathbf{I}_e e_j - \mathbf{F}_j x_j - \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}u_j \right)
\end{align}
Note that $\mathbf{I}_e=\mathbf{I}_x=\mathbf{I}_r$.
Now, we want to form a performance index that includes terms for 7 things 
\begin{itemize}
	\item a penalty on the size of the control input for each future iteration
	\item a penalty on the deviation in the control input for each future iteration
	\item a penalty on the size of the state for each future iteration
	\item a penalty on the deviation in the state for each future iteration
	\item a penalty on the size of the error for each future iteration
	\item a penalty on the deviation in the error for each future iteration
	\item an economic incentive on the state for each future iteration
\end{itemize}

We can write this as
\begin{align}
\mathbf{J}_{j+N} 
= \sum_{k=1}^{N}(
&   u_{j+k}^T Q_u u_{j+k} + \left(u_{j+k}-u_{j+k-1}\right)^T Q_{\delta u} \left(u_{j+k}-u_{j+k-1}\right) \\
& + x_{j+k}^T Q_x x_{j+k} + \left(x_{j+k}-x_{j+k-1}\right)^T Q_{\delta x} \left(x_{j+k}-x_{j+k-1}\right) \\
& + e_{j+k}^T Q_e e_{j+k} + \left(e_{j+k}-e_{j+k-1}\right)^T Q_{\delta e} \left(e_{j+k}-e_{j+k-1}\right) \\
& + S_x x_{j+k})\\
\end{align}
\begin{align}
\mathbf{J}_{j+N} 
= \sum_{k=1}^{N}(
&   u_{j+k}^T Q_u u_{j+k} 
  + x_{j+k}^T Q_x x_{j+k} 
  + e_{j+k}^T Q_e e_{j+k}
  + S_x x_{j+k}) +\\
&\sum_{k=1}^{N}(
  \left(u_{j+k}-u_{j+k-1}\right)^T Q_{\delta u} \left(u_{j+k}-u_{j+k-1}\right) \\
& + \left(x_{j+k}-x_{j+k-1}\right)^T Q_{\delta x} \left(x_{j+k}-x_{j+k-1}\right) \\
& + \left(e_{j+k}-e_{j+k-1}\right)^T Q_{\delta e} \left(e_{j+k}-e_{j+k-1}\right) 
)
\end{align}
\begin{align}
\mathbf{J}_{j+N} 
= \sum_{k=1}^{N}(
&   u_{j+k}^T Q_u u_{j+k} 
+ x_{j+k}^T Q_x x_{j+k} 
+ e_{j+k}^T Q_e e_{j+k}
+ S_x x_{j+k}) +\\
&\sum_{k=2}^{N}(
\left(u_{j+k}-u_{j+k-1}\right)^T Q_{\delta u} \left(u_{j+k}-u_{j+k-1}\right) \\
& + \left(x_{j+k}-x_{j+k-1}\right)^T Q_{\delta x} \left(x_{j+k}-x_{j+k-1}\right) \\
& + \left(e_{j+k}-e_{j+k-1}\right)^T Q_{\delta e} \left(e_{j+k}-e_{j+k-1}\right) 
)\\
&+
(u_{j+1}-u_{j})^T Q_{\delta u} (u_{j+1}-u_{j})
(x_{j+1}-x_{j})^T Q_{\delta x} (x_{j+1}-x_{j})
(e_{j+1}-e_{j})^T Q_{\delta e} (e_{j+1}-e_{j})
\end{align}
which has an equivalent block form
\begin{equation}
\begin{split}
\mathbf{J}_{j+N} = 
& \mathbf{u}_{j+1}^T \mathbf{Q_u} \mathbf{u}_{j+1} + \mathbf{u}_{j+1}^T \mathbf{D}_u^T \mathbf{Q_{\delta u}} \mathbf{D}_u \mathbf{u}_{j+1} + \left(u_{j+1}-u_j\right)^T Q_{\delta u} \left(u_{j+1}-u_j\right)\\
&+\mathbf{x}_{j+1}^T \mathbf{Q_x} \mathbf{x}_{j+1} + \mathbf{x}_{j+1}^T \mathbf{D}_x^T \mathbf{Q_{\delta x}} \mathbf{D}_x \mathbf{x}_{j+1} + \left(x_{j+1}-x_j\right)^T Q_{\delta x} \left(x_{j+1}-x_j\right)\\
&+\mathbf{e}_{j+1}^T \mathbf{Q_e} \mathbf{e}_{j+1} + \mathbf{e}_{j+1}^T \mathbf{D}_e^T \mathbf{Q_{\delta e}} \mathbf{D}_e \mathbf{e}_{j+1} + \left(e_{j+1}-e_j\right)^T Q_{\delta e} \left(e_{j+1}-e_j\right)\\
&+\mathbf{S_x}\mathbf{x}_{j+1}
\end{split}
\end{equation}
\begin{equation}
\begin{split}
\mathbf{J}_{j+N} = 
& \mathbf{u}_{j+1}^T \mathbf{Q_u} \mathbf{u}_{j+1} + \mathbf{u}_{j+1}^T \mathbf{D}_u^T \mathbf{Q_{\delta u}} \mathbf{D}_u \mathbf{u}_{j+1} 
+ \left(\mathbf{E}_u\mathbf{u}_{j+1}-u_j\right)^T Q_{\delta u} \left(\mathbf{E}_u\mathbf{u}_{j+1}-u_j\right)\\
&+\mathbf{x}_{j+1}^T \mathbf{Q_x} \mathbf{x}_{j+1} + \mathbf{x}_{j+1}^T \mathbf{D}_x^T \mathbf{Q_{\delta x}} \mathbf{D}_x \mathbf{x}_{j+1} 
+ \left(\mathbf{E}_x\mathbf{x}_{j+1}-x_j\right)^T Q_{\delta x} \left(\mathbf{E}_x\mathbf{x}_{j+1}-x_j\right)\\
&+\mathbf{e}_{j+1}^T \mathbf{Q_e} \mathbf{e}_{j+1} + \mathbf{e}_{j+1}^T \mathbf{D}_e^T \mathbf{Q_{\delta e}} \mathbf{D}_e \mathbf{e}_{j+1} 
+ \left(\mathbf{E}_e\mathbf{e}_{j+1}-e_j\right)^T Q_{\delta e} \left(\mathbf{E}_e\mathbf{e}_{j+1}-e_j\right)\\
&+\mathbf{S_x}\mathbf{x}_{j+1}
\end{split}
\end{equation}

\begin{align}
\mathbf{J}_{j+N} 
& = \mathbf{u}_{j+1}^T \left(\mathbf{Q_u} + \mathbf{D}_u^T\mathbf{Q_{\delta u}} \mathbf{D}_u + \mathbf{E}_u^T Q_{\delta u} \mathbf{E}_u \right) \mathbf{u}_{j+1} - 2u_j^T Q_u \mathbf{E}_u \mathbf{u}_{j+1} + u_j^T Q_u u_j\\
& + \mathbf{x}_{j+1}^T \left(\mathbf{Q_x} + \mathbf{D}_x^T\mathbf{Q_{\delta x}} \mathbf{D}_x + \mathbf{E}_x^T Q_{\delta x} \mathbf{E}_x \right) \mathbf{x}_{j+1} - 2x_j^T Q_x \mathbf{E}_x \mathbf{x}_{j+1} + x_j^T Q_x x_j\\
& + \mathbf{e}_{j+1}^T \left(\mathbf{Q_e} + \mathbf{D}_e^T\mathbf{Q_{\delta e}} \mathbf{D}_e + \mathbf{E}_e^T Q_{\delta e} \mathbf{E}_e \right) \mathbf{e}_{j+1} - 2u_j^T Q_e \mathbf{E}_e \mathbf{e}_{j+1} + e_j^T Q_u e_j\\
& + \mathbf{S_x}\mathbf{x}_{j+1}
\end{align}
Since we're going to differentiate, I'm going to drop the terms that don't depend on $\mathbf{u}_{j+1}$
\begin{align}
\mathbf{J}_{j+N} 
& = \mathbf{u}_{j+1}^T \left(\mathbf{Q_u} + \mathbf{D}_u^T\mathbf{Q_{\delta u}} \mathbf{D}_u + \mathbf{E}_u^T Q_{\delta u} \mathbf{E}_u \right) \mathbf{u}_{j+1} - 2u_j^T Q_u \mathbf{E}_u \mathbf{u}_{j+1} \\
& + \mathbf{x}_{j+1}^T \left(\mathbf{Q_x} + \mathbf{D}_x^T\mathbf{Q_{\delta x}} \mathbf{D}_x + \mathbf{E}_x^T Q_{\delta x} \mathbf{E}_x \right) \mathbf{x}_{j+1} - 2x_j^T Q_x \mathbf{E}_x \mathbf{x}_{j+1} \\
& + \mathbf{e}_{j+1}^T \left(\mathbf{Q_e} + \mathbf{D}_e^T\mathbf{Q_{\delta e}} \mathbf{D}_e + \mathbf{E}_e^T Q_{\delta e} \mathbf{E}_e \right) \mathbf{e}_{j+1} - 2u_j^T Q_e \mathbf{E}_e \mathbf{e}_{j+1} \\
& + \mathbf{S_x}\mathbf{x}_{j+1}
\end{align}
\begin{equation}
\mathbf{J}_{j+N} = 
\mathbf{u}_{j+1}^T \mathbf{\hat{Q}_u} \mathbf{u}_{j+1}- 2u_j^T Q_u \mathbf{E}_u \mathbf{u}_{j+1}\\
+\mathbf{x}_{j+1}^T \mathbf{\hat{Q}_x} \mathbf{x}_{j+1}- 2x_j^T Q_x \mathbf{E}_x \mathbf{x}_{j+1}\\
+\mathbf{e}_{j+1}^T \mathbf{\hat{Q}_e} \mathbf{e}_{j+1}- 2u_j^T Q_e \mathbf{E}_e \mathbf{e}_{j+1}\\
+\mathbf{S_x}\mathbf{x}_{j+1}
\end{equation}
where $\mathbf{\hat{Q}_u}$, $\mathbf{\hat{Q}_x}$, and $\mathbf{\hat{Q}_e}$ are defined appropriately

Now look at the gradient of each term with respect to $\mathbf{u}_{j+1}$,
\begin{equation}
\frac{d}{d\mathbf{u}_{j+1}} \left(\mathbf{u}_{j+1}^T \mathbf{\hat{Q}_u} \mathbf{u}_{j+1} - 2u_j^T Q_u \mathbf{E}_u \mathbf{u}_{j+1}\right)  
= 2 \mathbf{u}_{j+1}^T \mathbf{\hat{Q}_u} - 2u_j^T Q_u \mathbf{E}_u
\end{equation}

\begin{align}
\frac{d}{d\mathbf{u}_{j+1}}\left(\mathbf{x}_{j+1}^T \mathbf{\hat{Q}_x} \mathbf{x}_{j+1} - 2x_j^T Q_x \mathbf{E}_x \mathbf{x}_{j+1}\right)  
& = \frac{d}{d\mathbf{u}_{j+1}}\left(\left( \left(\mathbf{I}_x +\mathbf{F}_j \right)x_j + \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_u u_j \right) \right)^T \mathbf{\hat{Q}_x} \left( \left(\mathbf{I}_x +\mathbf{F}_j \right)x_j + \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_u u_j \right)\right) - 2x_j^T Q_x \mathbf{E}_x \mathbf{x}_{j+1}\right) \\
& =2 \left( \left(\mathbf{I}_x +\mathbf{F}_j \right)x_j + \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_u u_j \right) \right)^T \mathbf{\hat{Q}_x}\mathbf{G}_j  - 2x_j^T Q_x \mathbf{E}_x \mathbf{G}_j
\end{align}

\begin{align}
\frac{d}{d\mathbf{u}_{j+1}}\left(\mathbf{e}_{j+1}^T \mathbf{\hat{Q}_e} \mathbf{e}_{j+1}- 2u_j^T Q_e \mathbf{E}_e \mathbf{e}_{j+1}\right)
& = \frac{d}{d\mathbf{u}_{j+1}} \left(\left( \mathbf{I}_e e_j -\mathbf{F}_j x_j- \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_u u_j \right)\right)^T \mathbf{\hat{Q}_e} \left( \mathbf{I} e_j -\mathbf{F}_j x_j - \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_u u_j \right) \right) - 2u_j^T Q_e \mathbf{E}_e \mathbf{e}_{j+1} \right)\\
& = - 2  \left( \mathbf{I}_e e_j -\mathbf{F}_j x_j - \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_uu_j \right)\right)^T \mathbf{\hat{Q}_e} \mathbf{G}_j  + 2e_j^T Q_e \mathbf{E}_e \mathbf{G}_j
\end{align}

\begin{align}
\frac{d}{d\mathbf{u}_{j+1}} \mathbf{S}_x \mathbf{x}_{j+1} 
& = \frac{d}{d\mathbf{u}_{j+1}} \mathbf{S}_x \left(\left(\mathbf{I}_x +\mathbf{F}_j \right)x_j + \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_u u_j \right)\right)\\
& =  \mathbf{S}_x  \mathbf{G}_j
\end{align}

So then the gradient of the performance index is

\begin{align}
\frac{d}{d\mathbf{J}_{j+1}} 
& = 2 \mathbf{u}_{j+1}^T \mathbf{\hat{Q}_u} - 2u_j^T Q_u \mathbf{E}_u\\
& + 2 \left( \left(\mathbf{I}_x +\mathbf{F}_j \right)x_j + \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_u u_j \right) \right)^T \mathbf{\hat{Q}_x}\mathbf{G}_j  - 2x_j^T Q_x \mathbf{E}_x \mathbf{G}_j\\
& - 2  \left( \mathbf{I}_e e_j -\mathbf{F}_j x_j - \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_uu_j \right)\right)^T \mathbf{\hat{Q}_e} \mathbf{G}_j  + 2e_j^T Q_e \mathbf{E}_e \mathbf{G}_j\\
& + \mathbf{S}_x  \mathbf{G}_j
\end{align}

Setting that equal to the zero vector

\begin{align}
\vec{0}^T 
& =  \mathbf{u}_{j+1}^T \mathbf{\hat{Q}_u} - u_j^T Q_u \mathbf{E}_u\\
& +  \left( \left(\mathbf{I}_x +\mathbf{F}_j \right)x_j + \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_u u_j \right) \right)^T \mathbf{\hat{Q}_x}\mathbf{G}_j  - x_j^T Q_x \mathbf{E}_x \mathbf{G}_j\\
& -   \left( \mathbf{I}_e e_j -\mathbf{F}_j x_j - \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_uu_j \right)\right)^T \mathbf{\hat{Q}_e} \mathbf{G}_j  + e_j^T Q_e \mathbf{E}_e \mathbf{G}_j\\
& + \frac{1}{2}\mathbf{S}_x  \mathbf{G}_j
\end{align}

Transposing the left and right hand sides
\begin{align}
\vec{0}
& =  \mathbf{\hat{Q}_u} \mathbf{u}_{j+1} -  \mathbf{E}_u^T Q_u u_j\\
& +  \mathbf{G}_j^T \mathbf{\hat{Q}_x} \left( \left(\mathbf{I}_x +\mathbf{F}_j \right)x_j + \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_u u_j \right) \right)  -   \mathbf{G}_j^T \mathbf{E}_x^T Q_x x_j\\
& -  \mathbf{G}_j^T \mathbf{\hat{Q}_e} \left( \mathbf{I}_e e_j -\mathbf{F}_j x_j - \mathbf{G}_j \left(\mathbf{u}_{j+1} - \mathbf{I}_uu_j \right)\right)  +   \mathbf{G}_j^T \mathbf{E}_e^T Q_e e_j\\
& + \frac{1}{2} \mathbf{G}_j^T \mathbf{S}_x^T
\end{align}

Now multiply all the terms out
\begin{align}
\vec{0}
& =  \mathbf{\hat{Q}_u} \mathbf{u}_{j+1} -  \mathbf{E}_u^T Q_u u_j\\
& 
+ \mathbf{G}_j^T \mathbf{\hat{Q}_x} \mathbf{I}_x x_j 
+ \mathbf{G}_j^T \mathbf{\hat{Q}_x} \mathbf{F}_j x_j 
+ \mathbf{G}_j^T \mathbf{\hat{Q}_x} \mathbf{G}_j \mathbf{u}_{j+1} 
- \mathbf{G}_j^T \mathbf{\hat{Q}_x} \mathbf{G}_j \mathbf{I}_u u_j  
- \mathbf{G}_j^T \mathbf{E}_x^T Q_x x_j\\
& 
- \mathbf{G}_j^T \mathbf{\hat{Q}_e} \mathbf{I}_e e_j 
+ \mathbf{G}_j^T \mathbf{\hat{Q}_e} \mathbf{F}_j x_j 
+ \mathbf{G}_j^T \mathbf{\hat{Q}_e} \mathbf{G}_j \mathbf{u}_{j+1} 
- \mathbf{G}_j^T \mathbf{\hat{Q}_e} \mathbf{G}_j \mathbf{I}_u u_j 
+ \mathbf{G}_j^T \mathbf{E}_e^T Q_e e_j\\
& + \frac{1}{2} \mathbf{G}_j^T \mathbf{S}_x^T
\end{align}


Now gather $\mathbf{u}_{j+1}$, $\mathbf{u}_{j}$, $e_j$ and $x_j$ terms.
\begin{align}
\vec{0}
& 
= \mathbf{\hat{Q}_u} \mathbf{u}_{j+1} 
+ \mathbf{G}_j^T \mathbf{\hat{Q}_x} \mathbf{G}_j \mathbf{u}_{j+1} 
+ \mathbf{G}_j^T \mathbf{\hat{Q}_e} \mathbf{G}_j \mathbf{u}_{j+1} \\
& 
- \mathbf{E}_u^T Q_u u_j
- \mathbf{G}_j^T \mathbf{\hat{Q}_x} \mathbf{G}_j \mathbf{I}_u u_j  
- \mathbf{G}_j^T \mathbf{\hat{Q}_e} \mathbf{G}_j \mathbf{I}_u u_j \\
& 
- \mathbf{G}_j^T \mathbf{E}_x^T Q_x x_j
+ \mathbf{G}_j^T \mathbf{\hat{Q}_x} \mathbf{I}_x x_j 
+ \mathbf{G}_j^T \mathbf{\hat{Q}_x} \mathbf{F}_j x_j 
+ \mathbf{G}_j^T \mathbf{\hat{Q}_e} \mathbf{F}_j x_j\\
&
- \mathbf{G}_j^T \mathbf{\hat{Q}_e} \mathbf{I}_e e_j 
+ \mathbf{G}_j^T \mathbf{E}_e^T Q_e e_j\\
& + \frac{1}{2} \mathbf{G}_j^T \mathbf{S}_x^T
\end{align}
\begin{align}
\vec{0}
& 
=
\left(
\mathbf{\hat{Q}_u}
+ \mathbf{G}_j^T \mathbf{\hat{Q}_x} \mathbf{G}_j 
+ \mathbf{G}_j^T \mathbf{\hat{Q}_e} \mathbf{G}_j 
\right) \mathbf{u}_{j+1} \\
& 
- 
\left(
\mathbf{E}_u^T Q_u 
+ \mathbf{G}_j^T \mathbf{\hat{Q}_x} \mathbf{G}_j \mathbf{I}_u 
+ \mathbf{G}_j^T \mathbf{\hat{Q}_e} \mathbf{G}_j \mathbf{I}_u 
\right) u_j \\
&
-
\left(
 \mathbf{G}_j^T \mathbf{E}_x^T Q_x 
- \mathbf{G}_j^T \mathbf{\hat{Q}_x} \mathbf{I}_x  
- \mathbf{G}_j^T \mathbf{\hat{Q}_x} \mathbf{F}_j  
- \mathbf{G}_j^T \mathbf{\hat{Q}_e} \mathbf{F}_j 
\right) x_j\\
&
-
\left( \mathbf{G}_j^T \mathbf{\hat{Q}_e} \mathbf{I}_e 
- \mathbf{G}_j^T \mathbf{E}_e^T Q_e 
\right) e_j\\
& + \frac{1}{2} \mathbf{G}_j^T \mathbf{S}_x^T
\end{align}
\begin{align}
\vec{0}
& 
=
\left(
\mathbf{\hat{Q}_u}
+ \mathbf{G}_j^T \left(\mathbf{\hat{Q}_x} + \mathbf{\hat{Q}_e} \right)\mathbf{G}_j 
\right) \mathbf{u}_{j+1} \\
& 
- 
\left(
\mathbf{E}_u^T Q_u 
+ \mathbf{G}_j^T \left(\mathbf{\hat{Q}_x} +  \mathbf{\hat{Q}_e} \right) \mathbf{G}_j \mathbf{I}_u 
\right) u_j \\
&
- \mathbf{G}_j^T
\left(
\mathbf{E}_x^T Q_x 
- \mathbf{\hat{Q}_x} \mathbf{I}_x  
- \mathbf{\hat{Q}_x} \mathbf{F}_j  
- \mathbf{\hat{Q}_e} \mathbf{F}_j 
\right) x_j\\
&
-\mathbf{G}_j^T
\left( \mathbf{\hat{Q}_e} \mathbf{I}_e  
- \mathbf{E}_e^T Q_e 
\right) e_j\\
& + \frac{1}{2} \mathbf{G}_j^T \mathbf{S}_x^T
\end{align}


Solving this for $\mathbf{u}_{j+1}$ gives the optimal learning filters and the update law
\begin{align}
\mathbf{u}_{j+1} & = L_u u_j + L_e e_j + L_x x_j + L_c\\
L_0 & \triangleq \left(\mathbf{\hat{Q}_u} + \mathbf{G}_j^T \left(\mathbf{\hat{Q}_x} + \mathbf{\hat{Q}_e} \right)\mathbf{G}_j \right)^{-1}\\
L_u & \triangleq L_0\left(\mathbf{E}_u^T Q_u + \mathbf{G}_j^T \left(\mathbf{\hat{Q}_x} +  \mathbf{\hat{Q}_e} \right) \mathbf{G}_j \mathbf{I}_u \right)\\
L_x & \triangleq L_0\mathbf{G}_j^T\left(\mathbf{E}_x^T Q_x - \mathbf{\hat{Q}_x} \mathbf{I}_x  - \mathbf{\hat{Q}_x} \mathbf{F}_j  - \mathbf{\hat{Q}_e} \mathbf{F}_j \right)\\
L_e & \triangleq L_0 \mathbf{G}_j^T \left( \mathbf{\hat{Q}_e} \mathbf{I}_e - \mathbf{E}_e^T Q_e \right)\\
L_c & \triangleq -\frac{1}{2}L_0\mathbf{G}_j^T\mathbf{S}_x^T
\end{align}

\end{document}















